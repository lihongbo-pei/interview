# 场景题

## 08、在 2G 大小的文件中，找出高频 top100 的单词

> 统计几十个URL出现的次数，如何找到出现次数Top k的URL

1. 分块读取（内存控制）
我们可以按 4MB 为单位分块读取文件，使用 BufferReader 逐行读取避免内存溢出。我们也可以动态调整分块大小（根据实际内存情况）

2. 并行处理（性能优化）
使用线程池处理每个分块，**每个线程独立统计局部词频**，合并结果时使用 `ConcurrentHashMap` 保证线程安全。

3. 全局合并（高效聚合）
使用 Map.merge 方法进行原子累加，同步代码块保证并发安全

4. Top K 筛选（堆排序优化）
维护大小为 100 的最小堆，最终排序输出结果。
具体过程就是如果遍历到的词的出现次数**大于堆顶上词的出现次数**，那么可以用新遍历到的词替换堆顶的词，然后重新调整这个堆为小顶堆。当遍历完所有的文件后，这个小顶堆中的词就是出现频率最高的100个词。

1. 分块读取 → 2. 局部统计 → 3. 全局合并 → 4. 堆排序筛选

具体代码如下：

```java
import java.io.*;
import java.nio.file.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.stream.*;

public class Top100WordsFinder {

    private static final int CHUNK_SIZE = 4 * 1024 * 1024; // 4MB
    private static final int TOP_K = 100;

    public static void main(String[] args) throws IOException, InterruptedException {
        String filePath = "path/to/your/2G/file.txt"; // 替换为你的文件路径
        List<String> top100Words = findTop100Words(filePath);
        top100Words.forEach(System.out::println);
    }

    private static List<String> findTop100Words(String filePath) throws IOException, InterruptedException {
        // Step 1: 分块读取
        List<String> allLines = Files.readAllLines(Paths.get(filePath), StandardCharsets.UTF_8)
                .parallelStream()
                .collect(Collectors.toList());

        // Step 2: 局部统计
        Map<String, Long> wordCounts = new ConcurrentHashMap<>();
        allLines.parallelStream().forEach(line -> {
            String[] words = line.split("\\s+");
            for (String word : words) {
                word = word.toLowerCase(); // 转换为小写
                wordCounts.merge(word, 1L, Long::sum);
            }
        });

        // Step 3: 全局合并
        // 使用ConcurrentHashMap已经自动处理了并发合并

        // Step 4: Top K 筛选
        PriorityQueue<Map.Entry<String, Long>> heap = new PriorityQueue<>(
                TOP_K,
                (e1, e2) -> e2.getValue().compareTo(e1.getValue())
        );
        wordCounts.entrySet().forEach(entry -> {
            if (heap.size() < TOP_K) {
                heap.add(entry);
            } else if (entry.getValue() > heap.peek().getValue()) {
                heap.poll();
                heap.add(entry);
            }
        });

        return new ArrayList<>(heap);
    }
}
```

## 19、接口防刷怎么实现

> 服务端API限流怎么实现，令牌桶算法的缺陷

首先想到的是**限流**，比如使用**令牌桶或漏桶算法**，限制每个用户或 IP 的请求频率。然后可能需要验证码，特别是对于登录、注册等敏感接口。还有黑名单机制，自动封禁频繁违规的 IP 或用户账号。

另外，设备指纹和用户行为分析也是重要的一部分，可以通过收集客户端信息来识别唯一设备，分析请求模式是否异常。比如，正常用户不会在短时间内发起大量相同请求。

（1）IP 限流

分布式限流：使用 Redis + Lua 脚本实现原子化计数器（如令牌桶算法）。

```lua
-- KEYS[1]=限流Key（如ip:127.0.0.1），
-- ARGV[1]=时间窗口（秒），表示令牌桶的有效期。
-- ARGV[2]=最大请求数，即令牌桶的最大容量。
local key = KEYS[1]
local limit = tonumber(ARGV[2])
local window = tonumber(ARGV[1])
local current = redis.call('GET', key) or 0
if tonumber(current) >= limit then
    return 0 -- 触发限流
else
    redis.call('INCR', key)
    redis.call('EXPIRE', key, window)
    return 1 -- 允许通过
end
```

```java
String key = "rate_limit:ip" + clientIP;
boolean allowed = redisEval(luaScript, Colltecions.singletonList(key), "60", "100");
```

令牌桶算法的缺陷

1. **突发流量处理**：令牌桶算法允许突发流量，但如果令牌生成速度跟不上请求速度，可能会导致请求被拒绝。
2. **时间精度问题**：令牌生成和消耗的时间精度可能不够高，特别是在高并发场景下，可能导致令牌生成和消耗的不准确。
3. **资源消耗**：需要维护一个令牌桶，可能会消耗一定的内存和计算资源。
4. **复杂性**：算法实现相对复杂，需要考虑令牌生成和消耗的同步问题。
5. **不公平性**：如果多个客户端共享同一个令牌桶，可能会导致某些客户端的请求被不公平地限制。

（2）设备指纹识别

```java
// 生成设备指纹（示例）
public String generateDeviceFingerprint(HttpServletRequest request) {
    String userAgent = request.getHeader("User-Agent");
    String ip = request.getRemoteAddr();
    String acceptLanguage = request.getHeader("Accept-Language");
    return DigestUtils.md5Hex(ip + userAgent + acceptLanguage); // 简单哈希
}
```

更进一步，可以客户端埋点采集硬件参数（如屏幕分辨率、CPU 型号）。

（3）请求签名

客户端生成请求参数的有序拼接字符串。

使用 HMAC-SHA256 和密钥生成签名。

将签名附加到请求头

```java
// 客户端生成签名
String data = "param1=value1&param2=value2&timestamp=1620000000";
String signature = HmacUtils.hmacSha256Hex(apiKeySecret, data);
```


```java
// 服务端验证
String serverSign = HmacUtils.hmacSha256Hex(apiKeySecret, data);
if (!serverSign.equals(clientSign)) {
    throw new ApiSecurityException("签名无效");
}
```

（4）添加黑名单

自建黑名单库，自动封禁频繁触发规则的设备/IP。



## 一、高并发上传图片怎么设计？

参考阿里云对象存储OSS（Object Storage Service）

### 断点续传上传

通过断点续传上传的方式将文件上传到OSS前，您可以指定断点记录点。上传过程中，如果出现网络异常或程序崩溃导致文件上传失败时，将从断点记录处继续上传未上传完成的部分。

```java
OSS ossClient = OSSClientBuilder.create()
                    .endpoint(endpoint)
                    .credentialsProvider(credentialsProvider)
                    .clientConfiguration(clientBuilderConfiguration)
                    .region(region)
                    .build();
// 依次填写Bucket名称（例如examplebucket）以及Object完整路径（例如exampledir/exampleobject.txt），
// Object完整路径中不能包含Bucket名称。
UploadFileRequest uploadFileRequest = new UploadFileRequest("examplebucket","exampledir/exampleobject.txt");

// 指定上传的分片大小，单位为字节，取值范围为100 KB~5 GB。默认值为100 KB。
uploadFileRequest.setPartSize(1 * 1024 * 1024);
// 开启断点续传，默认关闭。
uploadFileRequest.setEnableCheckpoint(true);
// 记录本地分片上传结果的文件。上传过程中的进度信息会保存在该文件中，如果某一分片上传失败，再次上传时会根据文件中记录的点继续上传。上传完成后，该文件会被删除。
// 如果未设置该值，默认与待上传的本地文件同路径，名称为${uploadFile}.ucp。
uploadFileRequest.setCheckpointFile("yourCheckpointFile");

// 断点续传上传。
ossClient.uploadFile(uploadFileRequest);
```

### 分片上传流程

> 参考链接：https://help.aliyun.com/zh/oss/developer-reference/java-multipart-upload

OSS提供的**分片上传（Multipart Upload）**功能，将要上传的**较大文件（Object）**分成多个分片（Part）来分别上传，上传完成后再调用CompleteMultipartUpload接口将这些Part组合成一个Object来达到断点续传的效果。

分片上传（Multipart Upload）分为以下三个步骤：

1. 初始化一个分片上传事件。

   调用ossClient.initiateMultipartUpload方法返回OSS创建的全局唯一的uploadId。

2. 上传分片。

   调用ossClient.uploadPart方法上传分片数据。

   > **说明**
   >
   > - 对于同一个uploadId，分片号（PartNumber）标识了该分片在整个文件内的相对位置。如果使用同一个分片号上传了新的数据，则OSS上该分片已有的数据将会被覆盖。
   >
   > - OSS将收到的分片数据的MD5值放在ETag头内返回给用户。
   >
   > - OSS计算上传数据的MD5值，并与SDK计算的MD5值比较，如果不一致则返回InvalidDigest错误码。

3. 完成分片上传。

   所有分片上传完成后，调用ossClient.completeMultipartUpload方法将所有分片合并成完整的文件。

## 二、设计歌曲歌单专辑的分库分表

### （一）歌曲表分表

**按歌曲类型分表**

### 设计歌曲、专辑、歌单，字段和关系，怎么避免歌曲冗余？

（一）歌曲表（song_pop 表为例）

| 字段名     | 数据类型 | 描述                                       |
| ---------- | -------- | ------------------------------------------ |
| song\_id   | INT      | 歌曲 ID（主键）                            |
| song\_name | VARCHAR  | 歌曲名                                     |
| singer     | VARCHAR  | 歌手                                       |
| duration   | INT      | 歌曲时长（秒）                             |
| file\_path | VARCHAR  | 歌曲文件存储路径                           |
| lyrics     | TEXT     | 歌曲歌词（可选，根据存储策略可能压缩存储） |

（二）歌单表（playlist_private 表为例）

| 字段名         | 数据类型 | 描述            |
| -------------- | -------- | --------------- |
| playlist\_id   | INT      | 歌单 ID（主键） |
| playlist\_name | VARCHAR  | 歌单名称        |
| creator        | VARCHAR  | 创建者          |
| create\_time   | DATETIME | 创建时间        |
| description    | TEXT     | 歌单描述        |

（三）歌单与歌曲关联表（playlist_song 表为例）

| 字段名       | 数据类型 | 描述             |
| ------------ | -------- | ---------------- |
| playlist\_id | INT      | 歌单 ID（外键）  |
| song\_id     | INT      | 歌曲 ID（外键）  |
| add\_time    | DATETIME | 添加到歌单的时间 |

### 4、如果别人拿到了token，就可以冒名登录，如何解决这个问题？

1. 使用HTTPS

   确保所有通信都通过HTTPS进行，这样可以防止中间人攻击，避免令牌在传输过程中被窃取。

2. 令牌过期机制

   为令牌设置一个较短的有效期，这样即使令牌被窃取，攻击者也只有有限的时间可以使用它。

3. 刷新令牌（Refresh Token）

   使用刷新令牌机制。当用户登录时，生成两个令牌：一个访问令牌（Access Token）和一个刷新令牌（Refresh Token）。访问令牌有效期较短，刷新令牌有效期较长。当访问令牌过期时，用户可以使用刷新令牌获取一个新的访问令牌。

4. 令牌绑定

   将令牌与用户的IP地址或其他设备信息绑定。每次验证令牌时，检查这些信息是否匹配。如果IP地址或设备信息发生变化，令牌将无效。

5. 限制令牌的使用范围

   为令牌设置特定的使用范围（Scope），限制令牌可以访问的资源。这样即使令牌被窃取，攻击者也无法访问所有资源。

### 5、文章分享功能设计：设计一个能生成分享链接并统计分享次数的简单功能。

1、数据库设计：

- Articles 文章表
- Shares 分享记录表

2、后端设计

- 生成分享链接
- 统计分享次数

### 6、任务量非常大，几十万的任务请求，但每个任务持续时间非常短，有什么实现方案

这是一个典型的高并发、短任务场景，对于后端系统来说，需要从多个方面来优化和设计，以确保系统能够高效、稳定地处理大量的短任务请求。以下是一些可能的实现方案：

1. **前端负载均衡**：使用 Nginx 或 HAProxy 将请求分发到多个后端服务器。
2. **后端服务**：每个服务器启动多个线程/进程，使用线程池/进程池管理资源。
3. **消息队列**：将任务请求放入 RabbitMQ 或 Kafka，后端服务异步消费处理。
4. **缓存**：使用 Redis 缓存热点数据，减少数据库压力。
5. **数据库优化**：优化数据库索引，使用读写分离、分库分表。
6. **监控与告警**：使用 Prometheus 和 Grafana 监控系统状态，设置告警规则。
7. **限流与熔断**：使用令牌桶算法限流，使用 Hystrix 熔断。

### 7、超卖问题如何解决？

1. 数据库层面的解决方案

​	1.1 使用乐观锁

​	乐观锁通过版本号或时间戳来确保数据的一致性。在更新库存时，检查版本号或时间戳是否发生变化，如果发生变化则拒绝更新。

​	1.2 使用悲观锁

​	悲观锁通过数据库的锁机制来确保数据的一致性。在更新库存时，先锁定相关记录，确保在更新过程中不会被其他事务修改。

2. 应用层面的解决方案

​	2.1 使用分布式锁

​	在分布式系统中，可以使用分布式锁来确保同一时间只有一个线程可以更新库存。

​	2.2 使用队列

​	将所有更新库存的请求放入队列中，由一个后台线程逐个处理，确保库存更新的顺序性。

3. 业务逻辑层面的解决方案

​	3.1 预扣库存

​	在用户下单时，先预扣库存，确保库存数量足够后再生成订单。

​	3.2 超卖补偿机制

​	如果发生超卖，提供补偿机制，如退款、优惠券等，以减少用户损失。

### 8、如何设计一个短链系统？

短链的本质就是短链服务接收请求后，根据短链找到对应的长链地址，然后重定向让浏览器自动跳转到这个长链。核心是映射和重定向。

那后端怎么设计这个映射关系呢？

- 数据库自增ID：往数据库里插一条长链，就能得到一个自增id，比如用户访问 `dl.x/1` 这个链接，解析得到 1，主键一查就能拿到URL1，速度快，实现简单。缺点就是ID越来越长，短链就不短了，而且数字有规律，容易被别人暴力遍历，影响安全。

- 哈希算法：MurMurHash或者CRC32等哈希算法对长链进行哈希，得到一串固定长度的值，比如32位的，但注意哈希完之后数字还是一长串，比我们平时看的短链还是长一些。这时候可以做**进制转换**，把这个大数字从十进制转化成62进制。为啥是62，因为62进制可以用数字加大小写字母表示，字符种类多，就能用更短的长度表示更大的数。那转化后短链就变成了这种 `dl.x/2ucnWU` ，那这才像我们短信里见到的短链。

那最终大致的数据库表结构设计如下：

- id：主键
- short_url：短链
- long_url：原始长URL
- user_id：用户ID（如果需要关联用户）
- created_at：创建时间
- updated_at：更新时间

那注意短链这段需要建立索引，因为很常见的查询就是通过短链得到长链，那最后别忘了重定向。

那浏览器是怎么跳转呢？


是服务器返回301还是302状态码，并在location字段上写上长链。301是永久重定向浏览器会缓存，那下次不访问短链系统直接跳，能大大减轻短链服务的压力。302是临时重定向浏览器不缓存，每次都要请求短链服务，好处就是你能精确统计到每次访问的数据


那总结一下短链系统这道题啊，你只要记住这三点：

- 原理是映射+重定向

- 核心是哈希——62进制缩短

- 加分项是区分301和302

## 项目

### 1、大模型调用

ollamaChatClient 调用 `stream` 方法，返回的类型为 `Flux<ChatResponse>`，然后再把 streamResponse 中的 content 通过SSE发送出去。

```java
@Override
public void doDoctorStreamV3(String userName, String message) {

    // 保存用户发送的记录到数据库
    chatRecordService.saveChatRecord(userName, message, ChatTypeEnum.USER);

    Prompt prompt = new Prompt(new UserMessage(message));
    Flux<ChatResponse> streamResponse = ollamaChatClient.stream(prompt);

    List<String> list = streamResponse.toStream().map(chatResponse -> {
        String content = chatResponse.getResult().getOutput().getContent();

        SSEServer.sendMessage(userName, content, SSEMsgType.ADD);

        log.info(content);
        return content;
    }).collect(Collectors.toList());

    SSEServer.sendMessage(userName, "GG", SSEMsgType.FINISH);

    // 保存AI回复的记录到数据库
    String htmlResult = "";
    for (String s : list) {
        htmlResult += s;
    }
    chatRecordService.saveChatRecord(userName, htmlResult, ChatTypeEnum.BOT);

}
```

### 2、项目中websocket是用来做什么的？

在我的项目里，WebSocket 主要用来实现**实时的前后端双向通信**。
 传统的 HTTP 请求是一次性通信，前端只能在请求后拿到结果，而我的项目需要在处理视频流或摄像头检测时，把检测进度、处理状态、提示信息等实时反馈给前端。

因此我在 Flask 中集成了 `flask_socketio`：

1. **建立长连接**：用户打开检测页面时，WebSocket 会建立持续的连接，避免频繁发起请求。
2. **实时消息推送**：在视频或摄像头检测过程中，后端会不断向前端推送状态信息，比如“正在加载模型”、“处理完成，正在保存”、“视频转码进度”等。
3. **用户体验提升**：相比轮询，WebSocket 延迟更低，前端用户可以第一时间看到检测进度和结果，大大提升了交互体验。

总结一句话就是：**我用 WebSocket 来替代传统的轮询机制，保证检测过程中前端能够实时接收到后端的进度和消息通知，从而实现流畅的实时检测体验。**

### 3、MinIO

1、引入依赖，编写配置信息

2、创建一个 minioClient

3、minioClient 调用 putObject 方法

```java
public static String uploadFile(String bucketName, String objectName, InputStream inputStream, boolean needUrl) throws Exception {
        minioClient.putObject(
                PutObjectArgs.builder()
                        .bucket(bucketName)
                        .object(objectName)
                        .stream(inputStream, inputStream.available(), -1)
                        .build());
        if (needUrl) {
            String imageUrl = fileHost
                    + "/"
                    + bucketName
                    + "/"
                    + objectName;
            return imageUrl;
        }
        return "";
    }
```

